{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQl5Ig1qMPs",
        "outputId": "b8ab5e6f-cb0e-4325-b116-6502e05cbefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries loaded.\n"
          ]
        }
      ],
      "source": [
        "# ✅ CELL 1 — LIBRARIES & IMPORTS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from lightgbm import LGBMRegressor, early_stopping\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"✅ Libraries loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 2 — LOAD DATA\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/mw_pw_profiles.csv')\n",
        "print(\"Raw shape:\", df.shape)\n",
        "\n",
        "# Drop irrelevant/text columns\n",
        "df.drop([\n",
        "    'gender', 'balls_per_over', 'series_name', 'name_x', 'name_y',\n",
        "    'unique_name', 'key_bcci', 'key_bcci_2', 'key_bigbash', 'key_cricbuzz',\n",
        "    'key_cricheroes', 'key_crichq', 'key_cricinfo', 'key_cricinfo_2',\n",
        "    'key_cricinfo_3', 'key_cricingif', 'key_cricketarchive',\n",
        "    'key_cricketarchive_2', 'key_cricketworld', 'key_nvplay',\n",
        "    'key_nvplay_2', 'key_opta', 'key_opta_2', 'key_pulse', 'key_pulse_2',\n",
        "    'full_name', 'teams'\n",
        "], axis=1, inplace=True)\n",
        "\n",
        "# Label encode player_id and player_team ONLY\n",
        "le = LabelEncoder()\n",
        "df['player_id'] = le.fit_transform(df['player_id'])\n",
        "df['player_team'] = le.fit_transform(df['player_team'])\n",
        "\n",
        "print(\"✅ player_id and player_team encoded.\")\n",
        "\n",
        "# ✅ Keep opposition_team as TEXT for rolling!\n",
        "# We'll encode/drop later.\n",
        "\n",
        "# One-hot match type\n",
        "df = pd.get_dummies(df, columns=['match_type'], drop_first=True, dtype=int)\n",
        "\n",
        "print(\"✅ After basic clean:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "2jZAPxAiq5aJ",
        "outputId": "f9a682a1-c807-41b2-b0fb-3a4869fa24df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-805007746.py:3: DtypeWarning: Columns (32,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/sample_data/mw_pw_profiles.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw shape: (333848, 58)\n",
            "✅ player_id and player_team encoded.\n",
            "✅ After basic clean: (333848, 35)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   player_id match_id  start_date  runs_scored  player_out  balls_faced  \\\n",
              "0        922  1158348  21-08-2018         10.0         1.0         30.0   \n",
              "1        922  1182644  05-05-2019          8.0         1.0         18.0   \n",
              "2        922  1275107  09-09-2021          1.0         0.0          5.0   \n",
              "3        922  1275113  15-09-2021          0.0         0.0          0.0   \n",
              "4        922  1275125  14-09-2021          1.0         1.0         15.0   \n",
              "\n",
              "   fours_scored  sixes_scored  catches_taken  run_out_direct  ...  \\\n",
              "0           1.0           0.0            1.0             0.0  ...   \n",
              "1           1.0           0.0            0.0             0.0  ...   \n",
              "2           0.0           0.0            0.0             0.0  ...   \n",
              "3           0.0           0.0            0.0             0.0  ...   \n",
              "4           0.0           0.0            0.0             0.0  ...   \n",
              "\n",
              "   bowling_style  playing_role fantasy_score_batting  fantasy_score_bowling  \\\n",
              "0            NaN           NaN                   5.0                    8.0   \n",
              "1            NaN           NaN                   3.0                    0.0   \n",
              "2            NaN           NaN                   1.0                    0.0   \n",
              "3            NaN           NaN                   0.0                    0.0   \n",
              "4            NaN           NaN                  -5.0                    0.0   \n",
              "\n",
              "   fantasy_score_total  match_type_MDM  match_type_ODI  match_type_ODM  \\\n",
              "0                 17.0               0               0               0   \n",
              "1                  7.0               0               0               0   \n",
              "2                  5.0               0               0               0   \n",
              "3                  4.0               0               0               0   \n",
              "4                 -1.0               0               0               0   \n",
              "\n",
              "   match_type_T20  match_type_Test  \n",
              "0               1                0  \n",
              "1               1                0  \n",
              "2               1                0  \n",
              "3               1                0  \n",
              "4               1                0  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31d2cb98-17c0-425e-a32b-681c127e26d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_id</th>\n",
              "      <th>match_id</th>\n",
              "      <th>start_date</th>\n",
              "      <th>runs_scored</th>\n",
              "      <th>player_out</th>\n",
              "      <th>balls_faced</th>\n",
              "      <th>fours_scored</th>\n",
              "      <th>sixes_scored</th>\n",
              "      <th>catches_taken</th>\n",
              "      <th>run_out_direct</th>\n",
              "      <th>...</th>\n",
              "      <th>bowling_style</th>\n",
              "      <th>playing_role</th>\n",
              "      <th>fantasy_score_batting</th>\n",
              "      <th>fantasy_score_bowling</th>\n",
              "      <th>fantasy_score_total</th>\n",
              "      <th>match_type_MDM</th>\n",
              "      <th>match_type_ODI</th>\n",
              "      <th>match_type_ODM</th>\n",
              "      <th>match_type_T20</th>\n",
              "      <th>match_type_Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>922</td>\n",
              "      <td>1158348</td>\n",
              "      <td>21-08-2018</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>922</td>\n",
              "      <td>1182644</td>\n",
              "      <td>05-05-2019</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>922</td>\n",
              "      <td>1275107</td>\n",
              "      <td>09-09-2021</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>922</td>\n",
              "      <td>1275113</td>\n",
              "      <td>15-09-2021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>922</td>\n",
              "      <td>1275125</td>\n",
              "      <td>14-09-2021</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31d2cb98-17c0-425e-a32b-681c127e26d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31d2cb98-17c0-425e-a32b-681c127e26d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31d2cb98-17c0-425e-a32b-681c127e26d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8fddae3d-6a9e-4688-b820-0742d0e9fd93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fddae3d-6a9e-4688-b820-0742d0e9fd93')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8fddae3d-6a9e-4688-b820-0742d0e9fd93 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 3 — BASE RATE FEATURES\n",
        "\n",
        "df['strike_rate'] = (df['runs_scored'] / df['balls_faced']) * 100\n",
        "df['economy_rate'] = (df['runs_conceded'] / df['balls_bowled']) * 100\n",
        "df['economy'] = (df['runs_conceded'] / df['balls_bowled']) * 6\n",
        "\n",
        "df.drop([\n",
        "    'balls_faced', 'runs_conceded', 'balls_bowled',\n",
        "    'player_out', 'dot_balls_as_batsman', 'dot_balls_as_bowler',\n",
        "    'fantasy_score_batting', 'fantasy_score_bowling', 'out_kind',\n",
        "    'order_seen'\n",
        "], axis=1, inplace=True)\n",
        "\n",
        "df['start_date'] = pd.to_datetime(df['start_date'], format=\"%d-%m-%Y\")\n",
        "\n",
        "print(\"✅ Base features done:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "lUKys3tCriW5",
        "outputId": "b1304f5f-87ad-497f-8d64-a98e8a31fc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Base features done: (333848, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   player_id match_id start_date  runs_scored  fours_scored  sixes_scored  \\\n",
              "0        922  1158348 2018-08-21         10.0           1.0           0.0   \n",
              "1        922  1182644 2019-05-05          8.0           1.0           0.0   \n",
              "2        922  1275107 2021-09-09          1.0           0.0           0.0   \n",
              "3        922  1275113 2021-09-15          0.0           0.0           0.0   \n",
              "4        922  1275125 2021-09-14          1.0           0.0           0.0   \n",
              "\n",
              "   catches_taken  run_out_direct  run_out_throw  stumpings_done  ...  \\\n",
              "0            1.0             0.0            0.0             0.0  ...   \n",
              "1            0.0             0.0            0.0             0.0  ...   \n",
              "2            0.0             0.0            0.0             0.0  ...   \n",
              "3            0.0             0.0            0.0             0.0  ...   \n",
              "4            0.0             0.0            0.0             0.0  ...   \n",
              "\n",
              "   playing_role  fantasy_score_total  match_type_MDM  match_type_ODI  \\\n",
              "0           NaN                 17.0               0               0   \n",
              "1           NaN                  7.0               0               0   \n",
              "2           NaN                  5.0               0               0   \n",
              "3           NaN                  4.0               0               0   \n",
              "4           NaN                 -1.0               0               0   \n",
              "\n",
              "   match_type_ODM match_type_T20  match_type_Test  strike_rate  economy_rate  \\\n",
              "0               0              1                0    33.333333           NaN   \n",
              "1               0              1                0    44.444444           NaN   \n",
              "2               0              1                0    20.000000           NaN   \n",
              "3               0              1                0          NaN           NaN   \n",
              "4               0              1                0     6.666667           NaN   \n",
              "\n",
              "   economy  \n",
              "0      NaN  \n",
              "1      NaN  \n",
              "2      NaN  \n",
              "3      NaN  \n",
              "4      NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a293109f-fc57-44d2-b29e-8532b1141eef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_id</th>\n",
              "      <th>match_id</th>\n",
              "      <th>start_date</th>\n",
              "      <th>runs_scored</th>\n",
              "      <th>fours_scored</th>\n",
              "      <th>sixes_scored</th>\n",
              "      <th>catches_taken</th>\n",
              "      <th>run_out_direct</th>\n",
              "      <th>run_out_throw</th>\n",
              "      <th>stumpings_done</th>\n",
              "      <th>...</th>\n",
              "      <th>playing_role</th>\n",
              "      <th>fantasy_score_total</th>\n",
              "      <th>match_type_MDM</th>\n",
              "      <th>match_type_ODI</th>\n",
              "      <th>match_type_ODM</th>\n",
              "      <th>match_type_T20</th>\n",
              "      <th>match_type_Test</th>\n",
              "      <th>strike_rate</th>\n",
              "      <th>economy_rate</th>\n",
              "      <th>economy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>922</td>\n",
              "      <td>1158348</td>\n",
              "      <td>2018-08-21</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>922</td>\n",
              "      <td>1182644</td>\n",
              "      <td>2019-05-05</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>922</td>\n",
              "      <td>1275107</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>922</td>\n",
              "      <td>1275113</td>\n",
              "      <td>2021-09-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>922</td>\n",
              "      <td>1275125</td>\n",
              "      <td>2021-09-14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a293109f-fc57-44d2-b29e-8532b1141eef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a293109f-fc57-44d2-b29e-8532b1141eef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a293109f-fc57-44d2-b29e-8532b1141eef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-88e1f059-e075-4b48-8080-5e4fe5ab6697\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88e1f059-e075-4b48-8080-5e4fe5ab6697')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-88e1f059-e075-4b48-8080-5e4fe5ab6697 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 4 — ROLLING EWM\n",
        "\n",
        "features_to_span = [\n",
        "    'runs_scored', 'fours_scored', 'sixes_scored', 'catches_taken',\n",
        "    'run_out_direct', 'run_out_throw', 'stumpings_done', 'wickets_taken',\n",
        "    'bowled_done', 'lbw_done', 'maidens', 'strike_rate', 'economy_rate', 'economy'\n",
        "]\n",
        "\n",
        "spans = [1, 5, 10]\n",
        "\n",
        "for feat in features_to_span:\n",
        "    for span in spans:\n",
        "        df[f\"{feat}_{span}\"] = (\n",
        "            df.groupby('player_id')[feat]\n",
        "            .transform(lambda x: x.shift(1).ewm(span=span, adjust=False).mean())\n",
        "        )\n",
        "\n",
        "print(\"✅ Rolling EWM done:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "_boLi-FRrkuv",
        "outputId": "0d91aea2-80aa-4f22-f165-11455d0409e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Rolling EWM done: (333848, 70)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   player_id match_id start_date  runs_scored  fours_scored  sixes_scored  \\\n",
              "0        922  1158348 2018-08-21         10.0           1.0           0.0   \n",
              "1        922  1182644 2019-05-05          8.0           1.0           0.0   \n",
              "2        922  1275107 2021-09-09          1.0           0.0           0.0   \n",
              "3        922  1275113 2021-09-15          0.0           0.0           0.0   \n",
              "4        922  1275125 2021-09-14          1.0           0.0           0.0   \n",
              "\n",
              "   catches_taken  run_out_direct  run_out_throw  stumpings_done  ...  \\\n",
              "0            1.0             0.0            0.0             0.0  ...   \n",
              "1            0.0             0.0            0.0             0.0  ...   \n",
              "2            0.0             0.0            0.0             0.0  ...   \n",
              "3            0.0             0.0            0.0             0.0  ...   \n",
              "4            0.0             0.0            0.0             0.0  ...   \n",
              "\n",
              "   maidens_10  strike_rate_1  strike_rate_5  strike_rate_10  economy_rate_1  \\\n",
              "0         NaN            NaN            NaN             NaN             NaN   \n",
              "1         0.0      33.333333      33.333333       33.333333             NaN   \n",
              "2         0.0      44.444444      37.037037       35.353535             NaN   \n",
              "3         0.0      20.000000      31.358025       32.561983             NaN   \n",
              "4         0.0      20.000000      31.358025       32.561983             NaN   \n",
              "\n",
              "  economy_rate_5  economy_rate_10  economy_1  economy_5  economy_10  \n",
              "0            NaN              NaN        NaN        NaN         NaN  \n",
              "1            NaN              NaN        NaN        NaN         NaN  \n",
              "2            NaN              NaN        NaN        NaN         NaN  \n",
              "3            NaN              NaN        NaN        NaN         NaN  \n",
              "4            NaN              NaN        NaN        NaN         NaN  \n",
              "\n",
              "[5 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc60ac98-d3a3-4fa1-976a-a4ef4fc3cf00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_id</th>\n",
              "      <th>match_id</th>\n",
              "      <th>start_date</th>\n",
              "      <th>runs_scored</th>\n",
              "      <th>fours_scored</th>\n",
              "      <th>sixes_scored</th>\n",
              "      <th>catches_taken</th>\n",
              "      <th>run_out_direct</th>\n",
              "      <th>run_out_throw</th>\n",
              "      <th>stumpings_done</th>\n",
              "      <th>...</th>\n",
              "      <th>maidens_10</th>\n",
              "      <th>strike_rate_1</th>\n",
              "      <th>strike_rate_5</th>\n",
              "      <th>strike_rate_10</th>\n",
              "      <th>economy_rate_1</th>\n",
              "      <th>economy_rate_5</th>\n",
              "      <th>economy_rate_10</th>\n",
              "      <th>economy_1</th>\n",
              "      <th>economy_5</th>\n",
              "      <th>economy_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>922</td>\n",
              "      <td>1158348</td>\n",
              "      <td>2018-08-21</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>922</td>\n",
              "      <td>1182644</td>\n",
              "      <td>2019-05-05</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>922</td>\n",
              "      <td>1275107</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>37.037037</td>\n",
              "      <td>35.353535</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>922</td>\n",
              "      <td>1275113</td>\n",
              "      <td>2021-09-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>31.358025</td>\n",
              "      <td>32.561983</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>922</td>\n",
              "      <td>1275125</td>\n",
              "      <td>2021-09-14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>31.358025</td>\n",
              "      <td>32.561983</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 70 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc60ac98-d3a3-4fa1-976a-a4ef4fc3cf00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc60ac98-d3a3-4fa1-976a-a4ef4fc3cf00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc60ac98-d3a3-4fa1-976a-a4ef4fc3cf00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3789f71-750d-408b-83c4-e5aa7323b7ac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3789f71-750d-408b-83c4-e5aa7323b7ac')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3789f71-750d-408b-83c4-e5aa7323b7ac button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 5 — ADVANCED + ROUND 4\n",
        "\n",
        "print(\"✅ Adding advanced ratios, slopes, momentum, opposition...\")\n",
        "\n",
        "# Safe divide helper\n",
        "def safe_div(num, den):\n",
        "    return (num / den).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "\n",
        "# Ratios\n",
        "df['runs_scored_1_vs_5'] = safe_div(df['runs_scored_1'], df['runs_scored_5'])\n",
        "df['runs_scored_1_vs_10'] = safe_div(df['runs_scored_1'], df['runs_scored_10'])\n",
        "df['runs_scored_5_vs_10'] = safe_div(df['runs_scored_5'], df['runs_scored_10'])\n",
        "\n",
        "# Career avg runs\n",
        "df['career_avg_runs'] = (\n",
        "    df.groupby('player_id')['runs_scored']\n",
        "    .transform(lambda x: x.shift(1).expanding().mean())\n",
        ").fillna(0)\n",
        "\n",
        "# Trend slope\n",
        "def calc_trend_slope(x):\n",
        "    x = x.dropna()\n",
        "    if len(x) < 2: return 0\n",
        "    X = np.arange(len(x)).reshape(-1, 1)\n",
        "    y = x.values\n",
        "    return LinearRegression().fit(X, y).coef_[0]\n",
        "\n",
        "df['trend_slope_5'] = (\n",
        "    df.groupby('player_id')['runs_scored']\n",
        "    .transform(lambda x: x.shift(1).rolling(5, min_periods=2).apply(calc_trend_slope, raw=False))\n",
        ").fillna(0)\n",
        "\n",
        "df['days_since_last'] = df.groupby('player_id')['start_date'].diff().dt.days.fillna(0)\n",
        "\n",
        "# Strike rate lags & diffs\n",
        "df['strike_rate_5'] = df.groupby('player_id')['strike_rate'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
        "df['strike_rate_10'] = df.groupby('player_id')['strike_rate'].transform(lambda x: x.rolling(10, min_periods=1).mean().shift(1))\n",
        "df['strike_rate_momentum'] = df['strike_rate_5'] / (df['strike_rate_10'] + 1e-6)\n",
        "df['career_avg_strike_rate'] = df.groupby('player_id')['strike_rate'].transform('mean')\n",
        "df['strike_rate_diff_5'] = df['strike_rate_5'] - df['career_avg_strike_rate']\n",
        "\n",
        "# Economy lags & diffs\n",
        "df['economy_rate_5'] = df.groupby('player_id')['economy_rate'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
        "df['economy_rate_10'] = df.groupby('player_id')['economy_rate'].transform(lambda x: x.rolling(10, min_periods=1).mean().shift(1))\n",
        "df['economy_rate_momentum'] = df['economy_rate_5'] / (df['economy_rate_10'] + 1e-6)\n",
        "df['economy_rate_diff_5'] = df['economy_rate_5'] - df['economy_rate']\n",
        "\n",
        "# Interactions\n",
        "df['strike_rate_T20'] = df['strike_rate'] * df['match_type_T20']\n",
        "df['strike_rate_Test'] = df['strike_rate'] * df['match_type_Test']\n",
        "df['economy_rate_ODI'] = df['economy_rate'] * df['match_type_ODI']\n",
        "\n",
        "# ✅ Opposition trends\n",
        "df['opp_runs_conceded_5'] = df.groupby('opposition_team')['runs_scored'].transform(\n",
        "    lambda x: x.rolling(5, min_periods=1).mean().shift(1)\n",
        ")\n",
        "df['opp_wickets_conceded_5'] = df.groupby('opposition_team')['wickets_taken'].transform(\n",
        "    lambda x: x.rolling(5, min_periods=1).mean().shift(1)\n",
        ")\n",
        "\n",
        "print(\"✅ Advanced + momentum + opposition features done:\", df.shape)\n",
        "\n",
        "# Drop opposition_team now\n",
        "df.drop(['opposition_team'], axis=1, inplace=True)\n",
        "df.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv4Iawwlrm4t",
        "outputId": "c238549d-10e9-41f4-9b80-2167ae6ee3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adding advanced ratios, slopes, momentum, opposition...\n",
            "✅ Advanced + momentum + opposition features done: (333848, 86)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-3391377610.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
            "  df.fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 6: FINAL TRAIN-TEST SPLIT (LEAK-PROOF)\n",
        "\n",
        "print(\"Splitting train/test...\")\n",
        "\n",
        "# Make sure start_date is datetime\n",
        "df['start_date'] = pd.to_datetime(df['start_date'])\n",
        "\n",
        "cutoff_date = pd.to_datetime('2024-07-01')\n",
        "\n",
        "# ✅ 1️⃣ Train/test split\n",
        "train_df = df[df['start_date'] < cutoff_date].copy()\n",
        "test_df = df[df['start_date'] >= cutoff_date].copy()\n",
        "\n",
        "print(f\"Train shape: {train_df.shape} | Test shape: {test_df.shape}\")\n",
        "\n",
        "# ✅ 2️⃣ Align columns if needed\n",
        "for col in set(train_df.columns) - set(test_df.columns):\n",
        "    test_df[col] = 0\n",
        "for col in set(test_df.columns) - set(train_df.columns):\n",
        "    train_df[col] = 0\n",
        "test_df = test_df[train_df.columns]\n",
        "\n",
        "# ✅ 3️⃣ Remove ALL leaky columns (but KEEP the target!)\n",
        "bad_cols = [col for col in train_df.columns if (\n",
        "    ('fantasy' in col.lower() and col != 'fantasy_score_total')\n",
        "    or col in [\n",
        "        'runs_scored', 'wickets_taken', 'fours_scored', 'sixes_scored',\n",
        "        'bowled_done', 'lbw_done', 'maidens', 'strike_rate', 'economy_rate', 'economy'\n",
        "    ]\n",
        ")]\n",
        "print(\"🚫 Dropping leakers BEFORE split:\", bad_cols)\n",
        "\n",
        "train_df = train_df.drop(bad_cols, axis=1, errors='ignore')\n",
        "test_df = test_df.drop(bad_cols, axis=1, errors='ignore')\n",
        "\n",
        "# ✅ 4️⃣ Now safely split out X/y\n",
        "X_train = train_df.drop(['fantasy_score_total', 'match_id', 'start_date'], axis=1, errors='ignore')\n",
        "y_train = train_df['fantasy_score_total']\n",
        "\n",
        "X_test = test_df.drop(['fantasy_score_total', 'match_id', 'start_date'], axis=1, errors='ignore')\n",
        "y_test = test_df['fantasy_score_total']\n",
        "\n",
        "# ✅ Final check: should be empty lists\n",
        "print(f\"Remaining fantasy cols: {[col for col in X_train.columns if 'fantasy' in col.lower()]}\")\n",
        "print(f\"Remaining direct stat cols: {[col for col in X_train.columns if col in ['runs_scored', 'wickets_taken', 'fours_scored', 'sixes_scored', 'bowled_done', 'lbw_done', 'maidens']]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "relHqrV_rst9",
        "outputId": "bd95c625-aaef-4bcf-dc4e-f5993392b1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting train/test...\n",
            "Train shape: (299006, 85) | Test shape: (34842, 85)\n",
            "🚫 Dropping leakers BEFORE split: ['runs_scored', 'fours_scored', 'sixes_scored', 'wickets_taken', 'bowled_done', 'lbw_done', 'maidens', 'strike_rate', 'economy_rate', 'economy']\n",
            "Remaining fantasy cols: []\n",
            "Remaining direct stat cols: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyswarm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIws4-fB8pQK",
        "outputId": "9f090ad5-500c-4cd3-affd-f52bc0f45f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarm) (2.0.2)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4463 sha256=7c7e6a56e2a22e2e61d53363632a0c5f5ed9ae5cfbb78d7cef041d216cbff688\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/4f/ec/8970b83323e16aa95034da175454843947376614d6d5e9627f\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyswarm import pso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# List of all features\n",
        "feature_names = [f for f in X_train.columns if f not in ['strike_rate', 'economy_rate', 'economy']]\n",
        "num_features = len(feature_names)\n",
        "\n",
        "# Objective function for PSO: mask selects features\n",
        "def objective(mask):\n",
        "    # Convert float mask to binary (0 or 1)\n",
        "    mask_bin = np.round(mask).astype(int)\n",
        "    if np.sum(mask_bin) == 0:\n",
        "        return 1e6  # Penalize empty feature subset\n",
        "\n",
        "    # Select features based on mask\n",
        "    selected_features = [f for i, f in enumerate(feature_names) if mask_bin[i]==1]\n",
        "\n",
        "    # Train simple LightGBM on selected features\n",
        "    model = LGBMRegressor(\n",
        "        colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "        n_estimators=300, num_leaves=50, subsample=0.7, random_state=42\n",
        "    )\n",
        "    model.fit(X_train[selected_features], y_train)\n",
        "    y_pred = model.predict(X_test[selected_features])\n",
        "\n",
        "    # Return RMSE as fitness score\n",
        "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Lower and upper bounds: each feature can be 0 or 1\n",
        "lb = [0] * num_features\n",
        "ub = [1] * num_features\n",
        "\n",
        "# Run PSO\n",
        "best_mask, best_score = pso(objective, lb, ub, swarmsize=20, maxiter=10)\n",
        "\n",
        "# Convert to binary and get selected features\n",
        "best_mask_bin = np.round(best_mask).astype(int)\n",
        "best_features = [f for i, f in enumerate(feature_names) if best_mask_bin[i]==1]\n",
        "\n",
        "print(\"✅ PSO selected features:\", best_features)\n",
        "print(f\"✅ PSO best RMSE: {best_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqhsxT5aC1fF",
        "outputId": "dfc04b49-a1ff-46b6-ff93-a8b953b8795f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008016 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6638\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011000 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6694\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026382 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6230\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7136\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051732 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5187\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5366\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5888\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6985\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6180\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 29\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6001\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007787 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4866\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006862 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6137\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016647 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6069\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006063 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6390\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008280 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6902\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7419\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005983 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5471\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5261\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6125\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006909 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6437\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6140\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045347 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7631\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 41\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4984\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004996 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6178\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5412\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009300 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6631\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008224 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5179\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5416\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7174\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5501\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007189 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6437\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035629 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7127\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6563\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5897\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008787 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6442\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6134\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006892 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5222\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005835 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5947\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6630\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6688\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005893 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5384\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009045 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7628\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 41\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6433\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6375\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5654\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029818 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6129\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5177\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5655\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6911\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5930\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007843 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6652\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7139\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5858\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5389\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5414\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5884\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025544 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5168\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005991 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5919\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006851 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6591\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007059 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6958\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011294 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6144\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008533 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6865\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5944\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6377\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006777 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5680\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6164\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5687\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5920\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6410\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5681\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5140\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6420\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6350\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5652\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5870\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018587 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6824\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007146 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6147\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5930\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010290 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6848\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7205\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005351 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5877\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006973 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6345\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6454\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5915\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5416\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007494 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5440\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5683\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5169\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5135\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009636 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6235\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005873 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5208\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005779 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6618\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009030 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6162\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5604\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6863\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009594 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6199\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5947\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007224 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6158\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7170\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5666\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6079\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6174\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007852 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5410\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5664\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4904\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5661\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5423\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005053 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4884\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5666\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006004 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4454\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005985 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6165\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018585 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5654\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5351\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008206 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6169\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5905\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005927 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6168\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6140\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005498 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6123\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6178\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025483 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6179\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5397\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 29\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5919\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005257 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5155\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007954 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5916\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5415\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5391\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5917\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008068 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4666\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6176\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5940\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007489 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5678\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005500 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5675\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6681\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007256 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5907\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6689\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6160\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5652\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007781 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6175\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004702 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5652\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5920\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008951 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5162\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006173 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5920\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5927\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005044 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5901\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007002 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6176\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5942\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006909 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005347 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006073 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6431\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5911\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6438\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005007 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5902\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6162\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008140 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005310 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5671\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005287 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5919\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007740 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5411\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5927\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5925\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6182\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5906\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6178\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5686\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5922\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006808 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5944\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005380 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5911\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5926\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005494 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5671\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008679 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5923\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5663\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6177\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004805 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6147\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5924\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004865 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5392\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005223 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005498 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005484 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5908\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6181\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005131 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5924\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005882 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6183\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007741 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5912\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5919\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5663\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6178\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007276 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6402\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016329 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4902\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005940 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5418\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005865 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6178\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005379 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5921\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5677\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005540 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5673\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5677\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5924\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5928\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 34\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006039 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5932\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 35\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005228 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5922\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5414\n",
            "[LightGBM] [Info] Number of data points in the train set: 37942, number of used features: 31\n",
            "[LightGBM] [Info] Start training from score 44.503532\n",
            "Stopping search: maximum iterations reached --> 10\n",
            "✅ PSO selected features: ['player_id', 'catches_taken', 'stumpings_done', 'playing_role', 'match_type_MDM', 'match_type_ODI', 'match_type_ODM', 'match_type_T20', 'match_type_Test', 'runs_scored_10', 'sixes_scored_10', 'catches_taken_1', 'run_out_direct_10', 'run_out_throw_5', 'run_out_throw_10', 'stumpings_done_1', 'stumpings_done_10', 'wickets_taken_10', 'bowled_done_1', 'lbw_done_5', 'maidens_1', 'maidens_10', 'economy_rate_1', 'economy_rate_5', 'economy_rate_10', 'economy_1', 'economy_5', 'runs_scored_1_vs_5', 'runs_scored_1_vs_10', 'career_avg_runs', 'economy_rate_diff_5', 'strike_rate_T20', 'strike_rate_Test', 'economy_rate_ODI']\n",
            "✅ PSO best RMSE: 31.8673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lgbm = LGBMRegressor(\n",
        "    colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "    n_estimators=1000, num_leaves=50, subsample=0.7, random_state=42\n",
        ")\n",
        "best_lgbm.fit(X_train[best_features], y_train)\n",
        "\n",
        "y_pred = best_lgbm.predict(X_test[best_features])\n",
        "\n",
        "# Metrics\n",
        "print(\"✅ Final LightGBM with PSO-selected features:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3-OZlODTC4ng",
        "outputId": "f1f5841d-0172-44af-d005-e3e6d04d9984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-1945029417.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Get the final list of feature column names used in LightGBM training\n",
        "final_features = X_train.columns.tolist()\n",
        "\n",
        "# 2️⃣ Create a new DataFrame with ONLY those features from the full dataset\n",
        "features_df = df[final_features].copy()\n"
      ],
      "metadata": {
        "id": "zUmSNehthjh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CELL 7 — FINAL MODEL TRAIN & METRICS\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"Training final LightGBM with Round 4 features...\")\n",
        "\n",
        "best_lgbm = LGBMRegressor(\n",
        "    colsample_bytree=0.8,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=10,\n",
        "    n_estimators=1000,\n",
        "    num_leaves=50,\n",
        "    subsample=0.7,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_lgbm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_lgbm.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n✅ FINAL LightGBM Performance:\")\n",
        "print(f\"  MAE : {mae:.4f}\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  R²  : {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "wYqS8J5TupQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 CELL 9: SHAP EXPLAIN\n",
        "\n",
        "import shap\n",
        "\n",
        "print(\"Running SHAP explain...\")\n",
        "\n",
        "# ✅ Make sure your SHAP version matches LightGBM\n",
        "explainer = shap.Explainer(best_lgbm)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# ✅ SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test, max_display=15)\n"
      ],
      "metadata": {
        "id": "3WrcUthLRvHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"🏷️ Running PRUNE test: with vs. without player_id ...\")\n",
        "\n",
        "# 1️⃣ Pick your top SHAP features — for demo, let's say top 15\n",
        "top_features = [\n",
        "    'strike_rate', 'economy_rate', 'economy_rate_diff_5',\n",
        "    'opp_runs_conceded_5', 'strike_rate_momentum', 'trend_slope_5',\n",
        "    'days_since_last', 'catches_taken_10', 'career_avg_strike_rate',\n",
        "    'catches_taken_5', 'strike_rate_diff_5', 'runs_scored_5_vs_10',\n",
        "    'player_id', 'career_avg_runs', 'strike_rate_10'\n",
        "]\n",
        "\n",
        "# 2️⃣ Split WITH player_id\n",
        "X_train_with_id = X_train[top_features].copy()\n",
        "X_test_with_id = X_test[top_features].copy()\n",
        "\n",
        "# 3️⃣ Split WITHOUT player_id\n",
        "top_features_no_id = [f for f in top_features if f != 'player_id']\n",
        "X_train_no_id = X_train[top_features_no_id].copy()\n",
        "X_test_no_id = X_test[top_features_no_id].copy()\n",
        "\n",
        "# 4️⃣ Train LightGBM WITH player_id\n",
        "model_with_id = LGBMRegressor(\n",
        "    colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "    n_estimators=1000, num_leaves=50, subsample=0.7, random_state=42\n",
        ")\n",
        "model_with_id.fit(X_train_with_id, y_train)\n",
        "y_pred_with_id = model_with_id.predict(X_test_with_id)\n",
        "\n",
        "# 5️⃣ Train LightGBM WITHOUT player_id\n",
        "model_no_id = LGBMRegressor(\n",
        "    colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "    n_estimators=1000, num_leaves=50, subsample=0.7, random_state=42\n",
        ")\n",
        "model_no_id.fit(X_train_no_id, y_train)\n",
        "y_pred_no_id = model_no_id.predict(X_test_no_id)\n",
        "\n",
        "# 6️⃣ Compare\n",
        "print(\"\\n✅ PRUNED LightGBM WITH player_id:\")\n",
        "print(f\"  MAE : {mean_absolute_error(y_test, y_pred_with_id):.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_with_id)):.4f}\")\n",
        "print(f\"  R²  : {r2_score(y_test, y_pred_with_id):.4f}\")\n",
        "\n",
        "print(\"\\n✅ PRUNED LightGBM WITHOUT player_id:\")\n",
        "print(f\"  MAE : {mean_absolute_error(y_test, y_pred_no_id):.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_no_id)):.4f}\")\n",
        "print(f\"  R²  : {r2_score(y_test, y_pred_no_id):.4f}\")\n"
      ],
      "metadata": {
        "id": "oMi2e0OGE1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"⚡️ Running STACK vs BEST single LightGBM...\")\n",
        "\n",
        "# ✅ 1️⃣ Split a holdout from X_train to train meta model on out-of-folds\n",
        "X_base_train, X_meta, y_base_train, y_meta = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ 2️⃣ First, train base LightGBM on base split\n",
        "base_lgbm = LGBMRegressor(\n",
        "    colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "    n_estimators=1000, num_leaves=50, subsample=0.7, random_state=42\n",
        ")\n",
        "base_lgbm.fit(X_base_train, y_base_train)\n",
        "\n",
        "# ✅ 3️⃣ Get base preds for meta training + test\n",
        "meta_train_preds = base_lgbm.predict(X_meta)\n",
        "meta_test_preds = base_lgbm.predict(X_test)\n",
        "\n",
        "# ✅ 4️⃣ Meta model: simple ridge to blend base preds & stats\n",
        "# You can add more meta features if you want — here we keep it clean\n",
        "meta_X_train = np.vstack([meta_train_preds]).T\n",
        "meta_X_test = np.vstack([meta_test_preds]).T\n",
        "\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "meta_model.fit(meta_X_train, y_meta)\n",
        "\n",
        "# ✅ Final stack prediction\n",
        "stack_preds = meta_model.predict(meta_X_test)\n",
        "\n",
        "# ✅ Also fit a single best LightGBM on full X_train for direct comparison\n",
        "best_lgbm_direct = LGBMRegressor(\n",
        "    colsample_bytree=0.8, learning_rate=0.01, max_depth=10,\n",
        "    n_estimators=1000, num_leaves=50, subsample=0.7, random_state=42\n",
        ")\n",
        "best_lgbm_direct.fit(X_train, y_train)\n",
        "best_lgbm_preds = best_lgbm_direct.predict(X_test)\n",
        "\n",
        "# ✅ Metrics side by side\n",
        "print(\"\\n✅ STACKED LightGBM + Ridge meta:\")\n",
        "print(f\"  MAE : {mean_absolute_error(y_test, stack_preds):.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, stack_preds)):.4f}\")\n",
        "print(f\"  R²  : {r2_score(y_test, stack_preds):.4f}\")\n",
        "\n",
        "print(\"\\n✅ SINGLE LightGBM (all features, full data):\")\n",
        "print(f\"  MAE : {mean_absolute_error(y_test, best_lgbm_preds):.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, best_lgbm_preds)):.4f}\")\n",
        "print(f\"  R²  : {r2_score(y_test, best_lgbm_preds):.4f}\")\n"
      ],
      "metadata": {
        "id": "WXfn9nROJ8X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict_22_players_using_all_history(player_ids, full_df, model, X_train_cols, agg='mean'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        player_ids (list[int]): The 22 player IDs.\n",
        "        full_df (pd.DataFrame): The full historical dataset with engineered features.\n",
        "        model: The trained LightGBM model.\n",
        "        X_train_cols (list): Training feature columns.\n",
        "        agg (str): How to aggregate ('mean', 'sum', 'latest').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: player_id and final predicted score, sorted high to low.\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ 1. Filter only rows for given player IDs\n",
        "    players_df = full_df[full_df['player_id'].isin(player_ids)].copy()\n",
        "    if players_df.empty:\n",
        "        raise ValueError(\"❌ None of the given player_ids found in the dataframe!\")\n",
        "\n",
        "    # ✅ 2. Fill any missing feature columns\n",
        "    for col in X_train_cols:\n",
        "        if col not in players_df.columns:\n",
        "            players_df[col] = 0\n",
        "\n",
        "    X = players_df[X_train_cols]\n",
        "\n",
        "    # ✅ 3. Predict for every row\n",
        "    preds = model.predict(X)\n",
        "    players_df['predicted'] = preds\n",
        "\n",
        "    # ✅ 4. Aggregate per player\n",
        "    if agg == 'mean':\n",
        "        final_scores = players_df.groupby('player_id')['predicted'].mean().reset_index()\n",
        "    elif agg == 'sum':\n",
        "        final_scores = players_df.groupby('player_id')['predicted'].sum().reset_index()\n",
        "    elif agg == 'latest':\n",
        "        players_df = players_df.sort_values('start_date')\n",
        "        final_scores = players_df.groupby('player_id').tail(1)[['player_id', 'predicted']]\n",
        "    else:\n",
        "        raise ValueError(f\"❌ Unknown aggregation method: {agg}\")\n",
        "\n",
        "    # ✅ 5. Sort high to low\n",
        "    final_scores = final_scores.sort_values('predicted', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return final_scores\n"
      ],
      "metadata": {
        "id": "EYSnF8oSsxpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = predict_22_players_using_all_history(\n",
        "    player_ids=[1,2,3,4,5,6,7,8,9,10, 11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    full_df=df,\n",
        "    model=best_lgbm,\n",
        "    X_train_cols=X_train.columns.tolist(),\n",
        "    agg='mean'  # or 'sum' or 'latest'\n",
        ")\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "5sB1zLFds0hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 1️⃣ Top-11 MAE calculation function\n",
        "def top11_mae(y_true, y_pred, player_names):\n",
        "    df = pd.DataFrame({\n",
        "        'actual': y_true,\n",
        "        'predicted': y_pred,\n",
        "        'name': player_names\n",
        "    })\n",
        "\n",
        "    top11_actual = df.sort_values('actual', ascending=False).head(11)\n",
        "    top11_pred = df.sort_values('predicted', ascending=False).head(11)\n",
        "\n",
        "    merged = pd.merge(\n",
        "        top11_actual[['name', 'actual']],\n",
        "        top11_pred[['name', 'predicted']],\n",
        "        how='outer',\n",
        "        on='name'\n",
        "    ).fillna(0)\n",
        "\n",
        "    merged['abs_diff'] = np.abs(merged['actual'] - merged['predicted'])\n",
        "\n",
        "    mae_sum = merged['abs_diff'].sum()\n",
        "\n",
        "    print(\"\\n✅ Top-11 Comparison Table:\")\n",
        "    print(merged)\n",
        "\n",
        "    return mae_sum\n",
        "\n",
        "# ✅ 2️⃣ Inference pipeline function\n",
        "def predict_top11_for_match(match_id, cutoff_date, model, full_df):\n",
        "    match_players = full_df[full_df['match_id'] == match_id].copy()\n",
        "    print(f\"🔍 Found {len(match_players)} rows for match_id {match_id}\")\n",
        "\n",
        "    match_players = match_players[match_players['start_date'] < pd.to_datetime(cutoff_date)]\n",
        "    print(f\"🔍 After cutoff: {len(match_players)} rows remain\")\n",
        "\n",
        "    if match_players.empty:\n",
        "        raise ValueError(f\"❌ No valid players for match {match_id} before {cutoff_date}\")\n",
        "\n",
        "    X_cols = X_train.columns.tolist()\n",
        "\n",
        "    # Fill missing\n",
        "    missing_cols = set(X_cols) - set(match_players.columns)\n",
        "    print(f\"🧩 Missing cols for this match: {missing_cols}\")\n",
        "\n",
        "    for col in missing_cols:\n",
        "        match_players[col] = 0\n",
        "\n",
        "    X_match = match_players[X_cols].copy()\n",
        "\n",
        "    y_pred = model.predict(X_match)\n",
        "    y_true = match_players['fantasy_score_total'].values\n",
        "    player_names = match_players['player_id'].values\n",
        "\n",
        "    result = pd.DataFrame({\n",
        "        'player_id': player_names,\n",
        "        'predicted': y_pred,\n",
        "        'actual': y_true\n",
        "    }).sort_values('predicted', ascending=False).head(11)\n",
        "\n",
        "    print(\"\\n✅ Top-11 Predicted Players:\")\n",
        "    print(result)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "Sj7RxZxbK7TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "K = 11\n",
        "\n",
        "def evaluate_match(df, k=K):\n",
        "    # ✅ 1. Actual total for best possible team\n",
        "    actual_top_k = df['fantasy_score_total'].nlargest(k).values\n",
        "    actual_top_k_sum = actual_top_k.sum()\n",
        "\n",
        "    # ✅ 2. Indices of predicted top k by model\n",
        "    idx_pred_top_k = df['predicted_fantasy_score_total_exp'].nlargest(k).index\n",
        "\n",
        "    # ✅ 3. Actual scores of the predicted top k players\n",
        "    model1_actual_sum = df.loc[idx_pred_top_k, 'fantasy_score_total'].sum()\n",
        "\n",
        "    # ✅ 4. Model overlap % (same as before)\n",
        "    overlap_pct = model1_actual_sum / actual_top_k_sum if actual_top_k_sum != 0 else 0\n",
        "\n",
        "    # ✅ 5. Predicted scores of predicted top k players\n",
        "    predicted_top_k = df.loc[idx_pred_top_k, 'predicted_fantasy_score_total_exp'].values\n",
        "\n",
        "    # ✅ 6. MAPE: mean absolute % difference between rank-wise top k\n",
        "    abs_diff = abs(actual_top_k - predicted_top_k).sum()\n",
        "    mape = abs_diff / actual_top_k_sum if actual_top_k_sum != 0 else 0\n",
        "\n",
        "    return pd.Series({\n",
        "        'actual_top_11_sum': actual_top_k_sum,\n",
        "        'model1_actual_sum': model1_actual_sum,\n",
        "        'model1_%_of_optimal': overlap_pct,\n",
        "        'abs_diff': abs_diff,\n",
        "        'mape': mape,  # This is the per-match MAPE, but not what you want finally\n",
        "    })\n",
        "\n",
        "# Add predictions\n",
        "test_df_with_preds = test_df.copy()\n",
        "test_df_with_preds['predicted_fantasy_score_total_exp'] = best_lgbm.predict(X_test)\n",
        "\n",
        "# Apply per match\n",
        "evaluation_df = (\n",
        "    test_df_with_preds\n",
        "    .groupby('match_id', group_keys=False)\n",
        "    .apply(evaluate_match)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# ✅ Compute final overall MAPE: total abs diff over total actual sum\n",
        "total_abs_diff = evaluation_df['abs_diff'].sum()\n",
        "total_actual_top_11_sum = evaluation_df['actual_top_11_sum'].sum()\n",
        "overall_mape = 100*total_abs_diff / total_actual_top_11_sum if total_actual_top_11_sum != 0 else 0\n",
        "\n",
        "print(evaluation_df.head())\n",
        "print(f\"✅ Overall MAPE for the entire model: {overall_mape:.4f}\")\n"
      ],
      "metadata": {
        "id": "SxWhqf8ipKGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "9f9a24ec-bc96-41db-d9d0-32ff8d620f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of features of the model must match the input. Model n_features_ is 34 and input n_features is 72",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-510777230.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Add predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtest_df_with_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtest_df_with_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_fantasy_score_total_exp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Apply per match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1011\u001b[0m                 \u001b[0;34m\"Number of features of the model must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 \u001b[0;34mf\"match the input. Model n_features_ is {self._n_features} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 34 and input n_features is 72"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "ipZsNnvgX5kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "base_learners = [\n",
        "    ('linear', LinearRegression()),\n",
        "    ('bayes_ridge', BayesianRidge()),\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('extratrees', ExtraTreesRegressor(n_estimators=100, random_state=42)),\n",
        "    ('xgb', XGBRegressor(n_estimators=100, random_state=42)),\n",
        "    ('lgbm', LGBMRegressor(n_estimators=100, random_state=42)),\n",
        "    ('catboost', CatBoostRegressor(verbose=0, random_state=42)),\n",
        "    ('svm', SVR()),\n",
        "    ('knn', KNeighborsRegressor()),\n",
        "    ('mlp', MLPRegressor(max_iter=500, random_state=42))\n",
        "]\n"
      ],
      "metadata": {
        "id": "VMxdnPVsSR7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import numpy as np\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model_scores = []\n",
        "\n",
        "for name, model in base_learners:\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "    mean_rmse = np.mean(np.sqrt(-scores))\n",
        "    model_scores.append((name, mean_rmse))\n",
        "    print(f\"{name}: Mean CV RMSE = {mean_rmse:.4f}\")\n",
        "\n",
        "# Sort by lowest RMSE\n",
        "model_scores.sort(key=lambda x: x[1])\n",
        "selected_models = [name for name, score in model_scores[:6]]\n",
        "print(\"\\nSelected top 6 models:\", selected_models)\n"
      ],
      "metadata": {
        "id": "Zsk0gJgUSh9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "selected_learners = [\n",
        "    ('lgbm', LGBMRegressor(n_estimators=100, random_state=42)),\n",
        "    ('catboost', CatBoostRegressor(verbose=0, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('extratrees', ExtraTreesRegressor(n_estimators=100, random_state=42)),\n",
        "    ('xgb', XGBRegressor(n_estimators=100, random_state=42)),\n",
        "    ('bayes_ridge', BayesianRidge())\n",
        "]\n"
      ],
      "metadata": {
        "id": "FcragFRF_Hmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "# Filter the selected base learners\n",
        "#selected_learners = [learner for learner in base_learners if learner[0] in selected_models]\n",
        "\n",
        "# Meta model: LightGBM\n",
        "meta_model = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Stacking Regressor\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=selected_learners,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    passthrough=False,  # True passes original features too, try both later!\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_stacked = stacked_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "LpFMgOlzipzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Custom metric again\n",
        "top_11_pred_idx = np.argsort(y_pred_stacked)[-11:]\n",
        "top_11_actual_idx = np.argsort(y_test)[-11:]\n",
        "\n",
        "actual_scores_of_pred_top11 = y_test.iloc[top_11_pred_idx].sum()\n",
        "actual_scores_of_actual_top11 = y_test.iloc[top_11_actual_idx].sum()\n",
        "\n",
        "diff_ratio = (actual_scores_of_pred_top11 - actual_scores_of_actual_top11) / actual_scores_of_actual_top11\n",
        "\n",
        "print(f\"Stacked Ensemble Top-11 Diff Ratio: {diff_ratio:.4f}\")\n"
      ],
      "metadata": {
        "id": "dwGQ5rZeiq-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y_test, bins=20, alpha=0.7, label='Actual')\n",
        "plt.title('Actual Scores')\n",
        "plt.xlabel('Score')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(y_pred_stacked, bins=20, alpha=0.7, label='Predicted', color='orange')\n",
        "plt.title('Stacked Model Predicted Scores')\n",
        "plt.xlabel('Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L21Dod5git2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for name, model in selected_learners:\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Custom metric\n",
        "    top_11_pred_idx = np.argsort(y_pred)[-11:]\n",
        "    top_11_actual_idx = np.argsort(y_test)[-11:]\n",
        "\n",
        "    actual_scores_pred_top11 = y_test.iloc[top_11_pred_idx].sum()\n",
        "    actual_scores_actual_top11 = y_test.iloc[top_11_actual_idx].sum()\n",
        "\n",
        "    diff_ratio = (actual_scores_pred_top11 - actual_scores_actual_top11) / actual_scores_actual_top11\n",
        "\n",
        "    results.append((name, diff_ratio))\n",
        "    print(f\"{name} - Top-11 Diff Ratio: {diff_ratio:.4f}\")\n",
        "\n",
        "# Sort results best to worst\n",
        "results.sort(key=lambda x: abs(x[1]))\n",
        "print(\"\\n=== Single Base Model Results ===\")\n",
        "for name, score in results:\n",
        "    print(f\"{name}: Diff Ratio = {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "dxyYUm4v08KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- Assume y_test and y_pred are defined ---\n",
        "# For best LGBM model\n",
        "y_pred_lgbm = best_lgbm.predict(X_test)\n",
        "\n",
        "K = 11\n",
        "\n",
        "# ✅ 1. Get actual top K scores (true top 11)\n",
        "actual_top_k = y_test.nlargest(K).values\n",
        "actual_top_k_sum = actual_top_k.sum()\n",
        "\n",
        "# ✅ 2. Get indices of predicted top K\n",
        "idx_pred_top_k = np.argsort(y_pred_lgbm)[-K:]\n",
        "\n",
        "# ✅ 3. Get actual scores of the predicted top K\n",
        "predicted_top_k_actuals = y_test.iloc[idx_pred_top_k].values\n",
        "predicted_top_k_actuals_sum = predicted_top_k_actuals.sum()\n",
        "\n",
        "# ✅ 4. Diff Ratio\n",
        "diff_ratio = (predicted_top_k_actuals_sum - actual_top_k_sum) / actual_top_k_sum\n",
        "\n",
        "# ✅ 5. Top-11 MAE (Sum-based)\n",
        "# Just the total absolute difference divided by 11\n",
        "mae_sum_based = abs(predicted_top_k_actuals_sum - actual_top_k_sum) / K\n",
        "\n",
        "# ✅ 6. Top-11 MAE (Rank-wise)\n",
        "# Sort both for rank-wise alignment\n",
        "actual_top_k_sorted = np.sort(actual_top_k)[::-1]\n",
        "predicted_top_k_actuals_sorted = np.sort(predicted_top_k_actuals)[::-1]\n",
        "\n",
        "rankwise_abs_diff = np.abs(actual_top_k_sorted - predicted_top_k_actuals_sorted)\n",
        "mae_rankwise = rankwise_abs_diff.mean()\n",
        "\n",
        "# ✅ Print nicely\n",
        "print(\"🔹 LGBM Best Model Metrics 🔹\")\n",
        "print(f\"Top-11 Diff Ratio: {diff_ratio:.4f}\")\n",
        "print(f\"Top-11 MAE (Sum-based): {mae_sum_based:.4f}\")\n",
        "print(f\"Top-11 MAE (Rank-wise): {mae_rankwise:.4f}\")\n",
        "print(\"Actual top 11 sorted:\", actual_top_k_sorted)\n",
        "print(\"Predicted top 11 actuals sorted:\", predicted_top_k_actuals_sorted)\n",
        "\n"
      ],
      "metadata": {
        "id": "WHGDvYkk3j6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale predictions\n",
        "y_pred_scaled = 0.5 * y_pred_lgbm\n",
        "\n",
        "# Get indices of new predicted top 11\n",
        "idx_pred_top_k_scaled = np.argsort(y_pred_scaled)[-K:]\n",
        "predicted_top_k_actuals_scaled = y_test.iloc[idx_pred_top_k_scaled].values\n",
        "\n",
        "# Same metrics\n",
        "predicted_top_k_actuals_sum_scaled = predicted_top_k_actuals_scaled.sum()\n",
        "diff_ratio_scaled = (predicted_top_k_actuals_sum_scaled - actual_top_k_sum) / actual_top_k_sum\n",
        "mae_sum_based_scaled = abs(predicted_top_k_actuals_sum_scaled - actual_top_k_sum) / K\n",
        "\n",
        "actual_top_k_sorted = np.sort(actual_top_k)[::-1]\n",
        "predicted_top_k_actuals_sorted_scaled = np.sort(predicted_top_k_actuals_scaled)[::-1]\n",
        "rankwise_abs_diff_scaled = np.abs(actual_top_k_sorted - predicted_top_k_actuals_sorted_scaled)\n",
        "mae_rankwise_scaled = rankwise_abs_diff_scaled.mean()\n",
        "\n",
        "print(\"🔹 Scaled Predictions 🔹\")\n",
        "print(f\"Top-11 Diff Ratio: {diff_ratio_scaled:.4f}\")\n",
        "print(f\"Top-11 MAE (Sum-based): {mae_sum_based_scaled:.4f}\")\n",
        "print(f\"Top-11 MAE (Rank-wise): {mae_rankwise_scaled:.4f}\")\n"
      ],
      "metadata": {
        "id": "xl-9ULyK3kUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Use your real helper!\n",
        "def select_best_team(player_ids_text):\n",
        "    try:\n",
        "        # 1️⃣ Parse input\n",
        "        player_ids = [int(pid.strip()) for pid in player_ids_text.split(',')]\n",
        "        if len(player_ids) != 22:\n",
        "            return f\"❌ Please enter exactly 22 player IDs, you gave {len(player_ids)}\"\n",
        "\n",
        "        # 2️⃣ Call your real function\n",
        "        final_scores = predict_22_players_using_all_history(\n",
        "            player_ids=player_ids,\n",
        "            full_df=df,\n",
        "            model=best_lgbm,\n",
        "            X_train_cols=X_train.columns.tolist(),\n",
        "            agg='mean'  # Or 'latest' or 'sum'\n",
        "        )\n",
        "\n",
        "        # 3️⃣ Pick top 11\n",
        "        selected_team = final_scores.head(11)\n",
        "\n",
        "        # 4️⃣ Format output\n",
        "        result = \"✅ **Selected Best 11:**\\n\\n\"\n",
        "        for idx, row in selected_team.iterrows():\n",
        "            result += f\"• Player ID: {row['player_id']} → Predicted Score: {row['predicted']:.1f}\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {e}\"\n",
        "\n",
        "# ✅ Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=select_best_team,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=2,\n",
        "        placeholder=\"Example: 101, 102, 103, ..., 122\",\n",
        "        label=\"Enter 22 Player IDs (comma-separated)\"\n",
        "    ),\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"🏏 Fantasy Team Selector\",\n",
        "    description=(\n",
        "        \"Enter **22 player IDs** for your match squad. \"\n",
        "        \"This app predicts scores using your trained model \"\n",
        "        \"and selects the best possible **11-player team**.\"\n",
        "    ),\n",
        "    examples=[\n",
        "        [\"1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "QhfSZzlU6qf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dream11Env:\n",
        "    def __init__(self, player_pool, budget_limit=100):\n",
        "        self.player_pool = player_pool\n",
        "        self.budget_limit = budget_limit\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.selected_players = []\n",
        "        self.done = False\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        mask = self.player_pool['player_id'].isin(self.selected_players).astype(int)\n",
        "\n",
        "        # ✅ Keep only important features to reduce state size\n",
        "        important_columns = ['fantasy_score_total', 'avg_points', 'recent_form']\n",
        "        state = self.player_pool[important_columns].copy()\n",
        "        state['selected'] = mask\n",
        "\n",
        "        state = state.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "        return state.values.flatten().astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done or action in self.selected_players:\n",
        "            return self._get_state(), -100.0, self.done, {}  # Invalid: duplicate or finished\n",
        "\n",
        "        self.selected_players.append(action)\n",
        "\n",
        "        if len(self.selected_players) == 11:\n",
        "            self.done = True\n",
        "\n",
        "            team_df = self.player_pool[self.player_pool['player_id'].isin(self.selected_players)]\n",
        "            total_points = team_df['fantasy_score_total'].sum()\n",
        "\n",
        "            if len(set(team_df['team'])) > 7:\n",
        "                return self._get_state(), -500.0, self.done, {}  # Invalid: too many teams\n",
        "\n",
        "            return self._get_state(), total_points, self.done, {}\n",
        "\n",
        "        return self._get_state(), 0.0, self.done, {}\n"
      ],
      "metadata": {
        "id": "E8MKs6YYKZ9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
        "        super(DQN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(state_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, action_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr=1e-3, gamma=0.99):\n",
        "        self.model = DQN(state_dim, action_dim)\n",
        "        self.target = DQN(state_dim, action_dim)\n",
        "        self.target.load_state_dict(self.model.state_dict())\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.memory = deque(maxlen=1000)  # ✅ Smaller buffer\n",
        "        self.gamma = gamma\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "    def act(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.action_dim - 1)\n",
        "        state = torch.FloatTensor(state).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def train_step(self, batch_size):\n",
        "        if len(self.memory) < batch_size:\n",
        "            return\n",
        "\n",
        "        batch = self.sample(batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.FloatTensor(np.array(states))\n",
        "        actions = torch.LongTensor(np.array(actions)).unsqueeze(1)\n",
        "        rewards = torch.FloatTensor(np.array(rewards)).unsqueeze(1)\n",
        "        next_states = torch.FloatTensor(np.array(next_states))\n",
        "        dones = torch.FloatTensor(np.array(dones)).unsqueeze(1)\n",
        "\n",
        "        q_values = self.model(states).gather(1, actions)\n",
        "        with torch.no_grad():\n",
        "            q_next = self.target(next_states).max(1)[0].unsqueeze(1)\n",
        "            target_q = rewards + self.gamma * q_next * (1 - dones)\n",
        "\n",
        "        loss = nn.MSELoss()(q_values, target_q)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ✅ Free memory\n",
        "        del states, actions, rewards, next_states, dones, q_values, q_next, target_q, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def update_target(self):\n",
        "        self.target.load_state_dict(self.model.state_dict())\n"
      ],
      "metadata": {
        "id": "hqGD-aAhVRNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "env = Dream11Env(player_pool=df, budget_limit=100)\n",
        "state_dim = env._get_state().shape[0]\n",
        "action_dim = len(df)\n",
        "\n",
        "agent = DQNAgent(state_dim, action_dim)\n",
        "\n",
        "num_episodes = 500\n",
        "batch_size = 64\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    start_time = time.time()\n",
        "\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    while True:\n",
        "        action = agent.act(state, epsilon=0.1)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        agent.push((state, action, reward, next_state, done))\n",
        "        agent.train_step(batch_size)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    if episode % 20 == 0:\n",
        "        agent.update_target()\n",
        "        print(f\"Episode {episode}: Total Reward = {total_reward:.2f} \"\n",
        "              f\"(Time: {time.time() - start_time:.2f} sec)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "t40SG3LpVSmX",
        "outputId": "1db1fcb3-be81-4e19-8bc1-1020ebc4b222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['avg_points', 'recent_form'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3696220257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDream11Env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstate_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maction_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-791257756.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, player_pool, budget_limit)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbudget_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbudget_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-791257756.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_players\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-791257756.py\u001b[0m in \u001b[0;36m_get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# ✅ Keep only important features to reduce state size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimportant_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fantasy_score_total'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recent_form'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportant_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['avg_points', 'recent_form'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ZpNtHLYkAP",
        "outputId": "8f79622f-8c47-4e20-9a50-885efd01417d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Total Reward = 82442.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5k0NGKApYkb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}